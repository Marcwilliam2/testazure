{"cells":[{"cell_type":"markdown","metadata":{"id":"0fArcnMELXoF"},"source":["# README\n","\n","> This Google Colab Notebook includes the following:\n","\n","1. Loading `Pre-trained Word2Vec word embeddings`.\n","1. Training `our own Word embeddings using the Word2Vec algorithm (CBoW)`\n","1. Training a `Simple RNN using Keras for sentiment analysis` on `IMDB reviews dataset`.\n","\n","> References\n","\n","1. [NLP - Word Embedding with Gensim library for Text-Classification](https://michael-fuchs-python.netlify.app/2021/09/01/nlp-word-embedding-with-gensim-for-text-classification/)\n","1. [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n","1. [Text classification with an RNN](https://www.tensorflow.org/text/tutorials/text_classification_rnn)\n","1. [Machine Learning â€” Word Embedding & Sentiment Classification using Keras](https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456)\n","\n","> Notes:\n","\n","1. Make sure to run the notebook using `Google colab's free tier Nvidia T4 GPU`:\n","    - Runtime -> Change runtime type -> T4 GPU -> Save"]},{"cell_type":"markdown","metadata":{},"source":["# Loading Model"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["# import pickle\n","# # Load the model from the file\n","# file_path = r'D:\\AAST\\Semester 10\\Image Processing\\.Marc\\Labs\\Lab 2\\trained_model.pkl'\n","# with open(file_path, 'rb') as f:\n","#     loaded_model = pickle.load(f)"]},{"cell_type":"markdown","metadata":{},"source":["# Imports "]},{"cell_type":"code","execution_count":169,"metadata":{},"outputs":[],"source":["import re\n","import string\n","\n","import numpy as np\n","import pandas as pd\n","import gensim.downloader\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, SimpleRNN\n","from tensorflow.keras.initializers import Constant\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","import os\n","from azure.storage.blob import BlobServiceClient\n","import pickle\n","import logging\n","import json\n"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["\n","# Define the connection string\n","connection_string = \"DefaultEndpointsProtocol=https;AccountName=mystorageproject11;AccountKey=kQYwYpoZgb7W12FhVHSipbIRGAe9OUuibCTFhViwlObyVU3iHhqgH2UD1JLLBnqEf2x9/sgBz2yY+AStRYvDoQ==;EndpointSuffix=core.windows.net\"\n","\n","# Connect to Azure Blob Storage\n","blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n","container_name = \"myconatinerblob\"\n","blob_name = \"trained_model.pkl\"  # Adjust this to match the name of your model file in Blob Storage\n","\n","# Retrieve the model file from Blob Storage\n","blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n","model_bytes = blob_client.download_blob().readall()\n","\n","# Load the machine learning model\n","loaded_model = pickle.loads(model_bytes)\n"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords') "]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["# # For reproducible results\n","# SEED = 42\n","\n","# keras.utils.set_random_seed(SEED)\n","# tf.config.experimental.enable_op_determinism()"]},{"cell_type":"markdown","metadata":{"id":"V0u9B8HiyIos"},"source":["# Loading IMDB reviews dataset"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["# # Define the file path\n","# file_path = r\"D:\\AAST\\Semester 10\\Image Processing\\.Marc\\Labs\\Lab 2\\IMDB-Dataset.csv\"\n","\n","# # Read the dataset into a DataFrame\n","# df = pd.read_csv(file_path)\n"]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1820,"status":"ok","timestamp":1708617506220,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"cbX9O9oA4kO9","outputId":"0913e25a-b13f-4de5-b3a4-a9e314d87fa6"},"outputs":[],"source":["# df.shape"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708617506548,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"IXFznV4W4khW","outputId":"6875494e-9433-4483-98ec-5c3c98287524"},"outputs":[],"source":["# df.info()"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702049293550,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"L4y7Z03pV_x5","outputId":"1d65504d-50db-450d-8943-b02ec3504fc7"},"outputs":[],"source":["# df.head(10)"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702049294065,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"ijNWNmCN4kj1","outputId":"10085aac-5a96-49e9-fbae-389a846509ef"},"outputs":[],"source":["# df['sentiment'].value_counts()"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"p2OPqWbFVnOq"},"outputs":[],"source":["# df['sentiment_id'] = df['sentiment'].map({'negative': 0, 'positive': 1})"]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702049295592,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"Rk5QfxY_YYtD","outputId":"e9affd24-6af6-4215-c22e-8593ca01fd78"},"outputs":[],"source":["# df.head(n=10)"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702049296927,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"jIWe0NYyW9UJ","outputId":"774b85d9-8534-4624-ca80-03f229a0531b"},"outputs":[],"source":["# print(stopwords.words('english'))"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"5IfNyEa_ZiDV"},"outputs":[],"source":["# The set() function converts the list of stopwords into a set data structure.\n","# Checking if a word is present in the stopwords list becomes significantly faster using a set compared to iterating through a list. usefual in large data \n","#Sets, unlike lists, eliminate duplicates. This ensures that each stopword is only included once, saving memory and avoiding unnecessary processing.\n","\n","english_stop_words = set(stopwords.words('english'))"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"ZtytL-rWWgSa"},"outputs":[],"source":["# Apply some quick text pre-processing\n","\n","def preprocess(text):\n","  # Remove HTML\n","  html_remover= re.compile('<.*?>')\n","  text = re.sub(html_remover, '', text)\n","\n","  # Create a translation table to remove punctuation\n","  table = str.maketrans(\"\", \"\", string.punctuation)\n","\n","  # Remove punctuation using translate\n","  text = text.translate(table)\n","\n","  # Tokenize sentence (the punkt library) \n","  words = word_tokenize(text)  \n","\n","  # Remove Stop words and lower each word\n","  filtered_sentence = []\n","  for word in words:\n","      if word not in english_stop_words and word.isalpha():\n","          filtered_sentence.append(word.lower())\n","\n","  return filtered_sentence"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1702049299633,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"7eqdPEnMYMxC","outputId":"56369b86-3b29-4470-8c11-6d67f088e9cc"},"outputs":[],"source":["# sentence = \"The movie wasn't as good as i me my expected?\"\n","# preprocessed_sentence = preprocess(sentence)\n","\n","# preprocessed_sentence"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"79Jj1EGfRKp6"},"outputs":[],"source":["# df['filtered_reviews'] = df['review'].apply(preprocess) # Pre-process sentences"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1702049353230,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"7R6Q02bNRQlJ","outputId":"423791a4-87a1-467b-a598-eebcf9044637"},"outputs":[],"source":["# df.info()"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1702049353231,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"CIqr0IxjSAN7","outputId":"943073c0-fc82-4d51-e78a-c853333ad04c"},"outputs":[],"source":["# df.head()"]},{"cell_type":"markdown","metadata":{"id":"PcL37Xq43uKp"},"source":["# Word2Vec Pre-trained word embeddings"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":636937,"status":"ok","timestamp":1702039329198,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"SABufDkyUujJ","outputId":"443a6b26-383f-454d-fbcb-cfa7efd453d2"},"outputs":[],"source":["# # # NOTE: We can either use Pre-trained word embeddings (e.g. word embeddings generated using the word2vec algorithm provided by some organization (e.g. Google) after\n","# # # training on lots and lots of text (100 billion words)) or We can train our own word embeddings using the word2vec algorithm on our own data (IMDB sentiment dataset)\n","\n","# wv = gensim.downloader.load('word2vec-google-news-300')"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1702039329199,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"MTCRJhYiRirS","outputId":"bc76ee15-1879-4e8a-976f-2c8352157e18"},"outputs":[],"source":["# wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=3) # ========> king - man + woman"]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1702039329760,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"epyJsO4_ZVoi","outputId":"1d05bb40-4d49-4bc2-caa6-f91ae132b31d"},"outputs":[],"source":["# print(\"Vocab size:\", len(wv))                                      "]},{"cell_type":"code","execution_count":103,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1702039329760,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"c_7VbBPjRijq","outputId":"b40f798a-e6c5-4a23-8ca8-3a346aa5a6c8"},"outputs":[],"source":["# wv.most_similar(\"egypt\")"]},{"cell_type":"code","execution_count":104,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1702039329761,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"d_S5BY1bYVvC","outputId":"b94dae9f-61c0-46fb-d67b-13cfc062d9cb"},"outputs":[],"source":["# wv.most_similar(\"good\")"]},{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1702039329761,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"ixnY51W9Yv0r","outputId":"fd577804-fab6-4f34-91c8-2db34b6088b2"},"outputs":[],"source":["# wv.most_similar(\"bad\")"]},{"cell_type":"markdown","metadata":{"id":"DDx0DNpORltf"},"source":["# Training our own word embeddings using Word2Vec `(CBoW)`"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"00M8sR_sRp3C"},"outputs":[],"source":["# processed_sentences = df['filtered_reviews'].to_list() #Lists in Python are more flexible data structures compared to pandas DataFrames for text data\n","# processed_labels = df['sentiment_id'].to_numpy() #NumPy arrays offer several advantages for numerical data like sentiment IDs : effiency and memory management "]},{"cell_type":"code","execution_count":107,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1702049353232,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"JSXuxUH5WqV0","outputId":"b4db4fa5-1a06-4367-9bb9-81a35e29ab00"},"outputs":[],"source":["# len(processed_sentences)"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["# print(\"First 10 reviews :\",processed_labels [:10] )  \n","# print (\"Nb of rows (reviews) = \" , processed_labels.shape)"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1702049353232,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"8AiNicmEXbh6","outputId":"09c526e3-20ea-4103-97cf-d50659eef856"},"outputs":[],"source":["# print(df['review'].iloc[18400])\n","# print(processed_sentences[18400])\n","# print(processed_labels[18400])"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"hbEW1_XhX0_q"},"outputs":[],"source":["# EMBEDDING_DIM = 25 # The dimensionality of each word vector\n","# # Train our own word embeddings using the word2vec algorithm (CBoW) on IMDB sentiment dataset.\n","# model = gensim.models.Word2Vec(sentences=processed_sentences, vector_size=EMBEDDING_DIM, window=5, workers=8, min_count=1, sg=0)\n","# #workers =8 : nb of cpu\n","# #min_count =1 : minimum count of words \n","# #sg =0 : use the CGW algorithm \n"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1702049433761,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"kt68zEHyZFvq","outputId":"344e210d-af7f-4496-8be5-4155dc070847"},"outputs":[],"source":["# print(\"Vocab size:\", len(model.wv))"]},{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1702049433761,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"15lM6gDdYEbk","outputId":"89cfa85c-9cad-4de6-b2af-ff6571efaa71"},"outputs":[],"source":["# model.wv.most_similar(\"god\")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702049436921,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"Slez2NtoYs_S","outputId":"6d231906-3d73-430b-906d-2fecb0b5acf9"},"outputs":[],"source":["# model.wv.most_similar(\"bad\")"]},{"cell_type":"markdown","metadata":{"id":"c1Y4Ux6HGz84"},"source":["> `NOTE`: Our `custom word embeddings` seem to have correctly captured semantic relationships between words"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"brD0n8TXZnKS"},"outputs":[],"source":["# # Save word embeddings\n","\n","# filename=\"word-vectors.txt\"\n","# model.wv.save_word2vec_format(filename)"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"03GkVbf2Z-Ma"},"outputs":[],"source":["# # Load word embeddings\n","\n","# embeddings = {}\n","\n","# with open(filename, 'r', encoding='utf-8') as fin:\n","#   lines = fin.readlines()\n","#   lines = [line.strip() for line in lines]\n","\n","#   for line in lines:\n","#     elements = line.split()\n","#     word = elements[0]\n","#     vector = np.array(elements[1:], dtype=np.float32)\n","\n","#     embeddings[word] = vector"]},{"cell_type":"code","execution_count":116,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1702049442886,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"-CVvTsnha44r","outputId":"9079f8b4-2293-4ef0-c07b-7498a0bb539e"},"outputs":[],"source":["# embeddings[\"bad\"]"]},{"cell_type":"markdown","metadata":{"id":"FIdqvA9A3zCn"},"source":["# RNNs for Sentiment Analysis"]},{"cell_type":"code","execution_count":117,"metadata":{"id":"gZEikM6WbhyF"},"outputs":[],"source":["tokenizer = Tokenizer()\n","# tokenizer.fit_on_texts(processed_sentences) "]},{"cell_type":"code","execution_count":118,"metadata":{"id":"IlLw3QjWbuZC"},"outputs":[],"source":["# sequences = tokenizer.texts_to_sequences(processed_sentences) # Convert all sentences to integer id sequences"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1702049452394,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"hSkFK7XSb6cS","outputId":"58bda93d-1b4d-40a5-ea12-abfc4dc9110f"},"outputs":[],"source":["# print(df['review'].iloc[18400])\n","# print(processed_sentences[18400])\n","# print(sequences[18400])"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"0DcAOK8OcGdt"},"outputs":[],"source":["# max_length = max([len(sentence) for sentence in processed_sentences]) # => Max sequence length\n","# print(max_length)\n","\n","# # Note: max_length is too much, we will default to a more reasonable max_length\n","\n","# max_length = 128"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"nFLRhSuucGbK"},"outputs":[],"source":["# word_index = tokenizer.word_index"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1702049452395,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"n1xvnjt1iixH","outputId":"b367ee4c-8842-4868-caed-9a2da8ddc3e9"},"outputs":[],"source":["# type(word_index)"]},{"cell_type":"code","execution_count":123,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1702049452395,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"HoF59Er2cGYv","outputId":"50ba4a84-5c8f-4994-b1c9-7f062736163d"},"outputs":[],"source":["# print(\"Number of unique tokens:\", len(word_index))"]},{"cell_type":"code","execution_count":124,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1702049452396,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"gs6euqR3sngs","outputId":"96caea53-df3d-437e-af68-cfee26a248a6"},"outputs":[],"source":["# word_index['good']"]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1702049452723,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"j2SbYsBbcGWT","outputId":"20458d97-28e1-467e-d8b6-90254ce1a826"},"outputs":[],"source":["# # ex : if we have a sentence 120 words we add 8 padding characters to the messsage ( the padding characters are always 0 )\n","# padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post') # post : add the padding characters at the end of the short message \n","# padded_sequences.shape # retun ( nb of rows , max length)"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["# padded_sequences [2] #Here an example of the 2nd review after padding the rest of the sentence to zeros to reach the 128 maxlength "]},{"cell_type":"code","execution_count":127,"metadata":{"id":"34Yt4XzllpJV"},"outputs":[],"source":["# # Creating an embedding matrix to pass to the embedding layer of the RNN network\n","\n","# vocab_size = len(tokenizer.word_index) + 1\n","# embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n","\n","# for word, idx in word_index.items():\n","#   if idx > vocab_size:\n","#     continue\n","\n","#   embedding_vector = embeddings.get(word)\n","\n","#   if embedding_vector is not None:\n","#     embedding_matrix[idx] = embedding_vector"]},{"cell_type":"code","execution_count":128,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1702049453208,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"9ZajeSAxrpV9","outputId":"90cf6166-f57e-4bf5-df69-3824f373b809"},"outputs":[],"source":["# embedding_matrix.shape"]},{"cell_type":"code","execution_count":129,"metadata":{"id":"JucMnj15kwl7"},"outputs":[],"source":["# X_train, X_test, y_train, y_test = train_test_split(padded_sequences, processed_labels, test_size=0.1, shuffle=True, random_state=SEED, stratify=processed_labels)"]},{"cell_type":"code","execution_count":130,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1702049453209,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"Rh_pq-i_ll8C","outputId":"abe8ff96-cc42-444c-c62c-7507a4e4efad"},"outputs":[],"source":["# X_train.shape, y_train.shape, X_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":131,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1702049453209,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"zoemI_jSr4ie","outputId":"c9613312-f504-4f13-d1e4-d642c0fdc985"},"outputs":[],"source":["# X_train[0] "]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702049453209,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"cuBbuRnY8dNi","outputId":"d47329bb-c8a9-49a4-e85f-64917692aee5"},"outputs":[],"source":["# y_train[0]"]},{"cell_type":"code","execution_count":133,"metadata":{"id":"xSSSa7zJmAON"},"outputs":[],"source":["# model = Sequential()\n","\n","# # Initialize our embedding layer with our custom trained word embeddings\n","# model.add(Embedding(vocab_size, EMBEDDING_DIM, embeddings_initializer=Constant(embedding_matrix), input_length=max_length, trainable=False))\n","# model.add(SimpleRNN(units=16, return_sequences=False, activation='relu'))\n","# model.add(Dense(16, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))"]},{"cell_type":"code","execution_count":134,"metadata":{"id":"Ho8Hdg_XmCLd"},"outputs":[],"source":["# model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":135,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1702049524236,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"Nswj96_BmC-m","outputId":"b835167e-9349-4e28-8772-ed5de34f23ee"},"outputs":[],"source":["# print(model.summary())"]},{"cell_type":"code","execution_count":136,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322606,"status":"ok","timestamp":1702049849473,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"qN8EdgTOmIHk","outputId":"98d0cfde-abaf-4e29-eafc-36a73441c0ce"},"outputs":[],"source":["# model.fit(x=X_train, y=y_train, epochs=100, validation_data=(X_test, y_test), verbose=1, batch_size=2048, callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)])"]},{"cell_type":"code","execution_count":137,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1958,"status":"ok","timestamp":1702049851415,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"7AR5ldecmVYJ","outputId":"3f108267-63b4-4106-c364-023f46670631"},"outputs":[],"source":["# preds = (model.predict(X_test) > 0.5).astype(\"int32\")"]},{"cell_type":"code","execution_count":138,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1702049851416,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"wdHeJppWmWK0","outputId":"92225d3f-303f-4dc9-d288-146f19da405f"},"outputs":[],"source":["# print(classification_report(y_test, preds))"]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[],"source":["def main(req):\n","    try:\n","        # Get the text from the request body\n","        req_body = req.get_json()\n","        text = req_body.get('text')\n","\n","        if not text:\n","            logging.error('No text found in request body')\n","            return ('Error: No text found in request body', 400)\n","\n","        # Process input data from examples\n","        examples = [\n","            \"I really don't understand the plot of this movie\",\n","            \"what a brilliant set of characters\",\n","            \"What a masterpiece !!!\",\n","            \"Couldn't get through the first 5 minutes\",\n","            \"Boring\",\n","            \"Very nicely executed\",\n","            \"Should have been given an oscar\",\n","            \"ahmed yehia saiddd that the film is sooo soo excited \",\n","            \"i feel sad\",\n","            \"negative\",\n","            \"zero\",\n","            \"THE FILM IS SO boring and rude actors\",\n","            \"This restaurant has terrible service\",\n","            \"The food was awful and overpriced\",\n","            \"I wouldn't recommend this place to anyone\",\n","            \"The staff was rude and unprofessional\",\n","            \"Worst dining experience ever\",\n","            \"I got sick after eating here\",\n","            \"The hygiene standards are appalling\",\n","            \"Save your money and go elsewhere\"\n","        ]\n","\n","        # Add the text from the request to the examples list\n","        if text:\n","            examples.append(text)\n","\n","        cleaned_examples = [preprocess(example) for example in examples]\n","        encoded_examples = tokenizer.texts_to_sequences(cleaned_examples)\n","        padded_examples = pad_sequences(encoded_examples, maxlen=128, padding='post')\n","\n","        # Make predictions using loaded_model\n","        predictions = loaded_model.predict(padded_examples)\n","        preds = [1 if prediction > 0.5 else 0 for prediction in predictions]\n","        label_preds = [\"Positive\" if pred == 1 else \"Negative\" for pred in preds]\n","\n","        # Return predictions as JSON with Content-Type header\n","        headers = {\n","            \"Content-Type\": \"application/json\"\n","        }\n","        return json.dumps({\"predictions\": label_preds}), 200, headers\n","    except Exception as e:\n","        logging.error(f'An error occurred: {str(e)}')\n","        return ('An error occurred', 500)\n"]},{"cell_type":"code","execution_count":150,"metadata":{},"outputs":[],"source":["# def is_valid_json(my_json_string):\n","#     try:\n","#         json.loads(my_json_string)\n","#         return True\n","#     except ValueError:\n","#         return False\n","\n","# # Usage:\n","# response_from_function =   # Replace with your actual response\n","# if is_valid_json(response_from_function):\n","#     print(\"Valid JSON\")\n","# else:\n","#     print(\"Invalid JSON\")\n"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 40ms/step\n"]}],"source":["# class RequestMock:\n","#     def __init__(self, json_data):\n","#         self.json_data = json_data\n","\n","#     def get_json(self):\n","#         return self.json_data\n","\n","# req = RequestMock({\"text\": \"boring\"})\n","# result = main(req)\n"]},{"cell_type":"code","execution_count":171,"metadata":{"id":"J60GxtLInc29"},"outputs":[],"source":["# examples = [\n","#     \"I really don't understand the plot of this movie\",\n","#     \"what a briliant set of characters\",\n","#     \"What a masterpiece !!!\",\n","#     \"Couldn't get through the first 5 minutes\",\n","#     \"Boring\",\n","#     \"Very nicely executed\",\n","#     \"Should have been given an oscar\",\n","#     \"ahmed yehia saiddd that the film is sooo soo excited \",\n","#     \"i felel sad\", \n","#     \"negative\", \n","#     \"zero\", \n","#     \"THE FILM IS SO boring and rude actors\",\n","#     \"This restaurant has terrible service\",\n","#     \"The food was awful and overpriced\",\n","#     \"I wouldn't recommend this place to anyone\",\n","#     \"The staff was rude and unprofessional\",\n","#     \"Worst dining experience ever\",\n","#     \"I got sick after eating here\",\n","#     \"The hygiene standards are appalling\",\n","#     \"Save your money and go elsewhere\"\n","# ]\n"]},{"cell_type":"code","execution_count":172,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702049983980,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"liVWKMsCnhjN","outputId":"2c7414e4-135f-41f4-a974-30ff28d5bd53"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 690ms/step\n"]}],"source":["# cleaned_examples = [preprocess(example) for example in examples] # Preprocess Each sequences\n","# encoded_examples = tokenizer.texts_to_sequences(examples) # Convert each word to an integer id\n","# padded_examples = pad_sequences(encoded_examples, maxlen=128, padding='post') # Pad each sequence to the max_length for batching\n","# predictions = loaded_model.predict(padded_examples) # Predict the label for each example\n","\n","# preds = [1 if prediction > 0.5 else 0 for prediction in predictions]\n","# label_preds = [\"Positive\" if pred == 1 else \"Negative\" for pred in preds]"]},{"cell_type":"code","execution_count":173,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702049983980,"user":{"displayName":"Ibrahim Amin","userId":"10030491037515309031"},"user_tz":-120},"id":"II7CFnk9npo1","outputId":"350b3a09-4c10-4f2a-e06c-4b7be74497bf"},"outputs":[],"source":["# for example, prediction in zip(examples, label_preds):\n","#   print(f\"Example: {example}\")\n","#   print(f\"Sentiment: {prediction}\\n\")"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[],"source":["\n","# def main(req):\n","#     # Process input data from examples\n","#     cleaned_examples = [preprocess(example) for example in examples]\n","#     encoded_examples = tokenizer.texts_to_sequences(cleaned_examples)\n","#     padded_examples = pad_sequences(encoded_examples, maxlen=128, padding='post')\n","    \n","#     # Make predictions using loaded_model\n","#     predictions = loaded_model.predict(padded_examples)\n","#     preds = [1 if prediction > 0.5 else 0 for prediction in predictions]\n","#     label_preds = [\"Positive\" if pred == 1 else \"Negative\" for pred in preds]\n","\n","#     return {\"predictions\": label_preds}"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[],"source":["# # Call the main function\n","# result = main(None)  # Pass None as req since we're not using it in this case\n","\n","# # Print the predictions\n","# print(result)"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[],"source":["# from flask import Flask \n","# app = Flask(__name__)\n","# @app.route('/api')\n","# def helloworld():\n","#     return prediction\n","# if __name__ == '__main__':\n","#     app.run(host='0.0.0.0', port=5000)  "]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[],"source":["# import pickle\n","# # Save the model to a file\n","# file_path = r'D:\\AAST\\Semester 10\\Image Processing\\.Marc\\Labs\\Lab 2\\trained_model.pkl'\n","# with open(file_path, 'wb') as f:\n","#     pickle.dump(model, f)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNYxXTtS6ak9X7MKalVL+r1","collapsed_sections":["LE7LX1o7MK5o","V0u9B8HiyIos","PcL37Xq43uKp","DDx0DNpORltf","FIdqvA9A3zCn"],"mount_file_id":"1PNBM9t8kAgX8hklLoFcH0ry_vbHLAaro","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
